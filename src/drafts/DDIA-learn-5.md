---
layout: post
title: DDIA Learning - 5
categories: [Book, Learn]
description: 数据密集型应用 - 读书笔记
keywords: Architecture, Learn
---

# 第五章 - 数据复制

复制主要指通过互联网络在多台机器上保存想通数据的副本，通过数据复制方案人们通常希望达到以下目的：

- 使数据在地理位置上更接近用户，从而降低访问延迟
- 当部分组件出现故障，系统依然可以继续工作，从而提高可用性
- 扩展至多台机器以同时提供数据访问服务，从而提高吞吐量

## 主节点与从节点

对于每笔数据写入，所有副本都需要随之更新：否则， 某些副本将出现不一致。最常见的解决方案是基于主节点的复制（也称为主动／被动，或主从复制）

1. 指定某一个副本为主副本 （或称为主节点） 。当客户写数据库时，必须将写请求首先发送给主副本，主副本首先将新数据写入本地存储。
2. 其他副本则全部称为从副本（或称为从节点）注 。主副本把新数据写入本地存储后，然后将数据更改作为复制的日志或更改流发送给所有从副本。每个从副本获得更改日志之后将其应用到本地，且严格保持与主副本相同的写入顺序。
3. 客户端从数据库中读数据 ，可以在主副本或者从副本上执行查询。再次强调，只有主副本才可以接受写请求 ：从客户端的角度来看，从副本都是只读的。

### 同步复制与异步复制

**区别**

- 同步复制中，主节点需要等待从节点确认完成了写入，之后才会进行后续处理（如发送 response 向用户报告完成）
- 异步复制中，主节点向从节点发送复制消息之后立即返回，不用等待从节点的完成确认

可以看到，异步复制可能会存在延迟，从而导致某些从节点的数据和主节点的数据不一致。有些情况下，从节点可能落后主节点几分钟甚至更长时间，例如，由于从节点刚从故障中恢复，或者系统已经接近最大设计上限，或者节点之间的网络出现问题

**同步复制优缺点**

- 优点：一旦向用户确认，从节点可以明确保证完成了与主节点的更新同步，数据已经处于最新版本。万一主节点发生故障，总是可以在从节点继续访问最新数据。
- 缺点：如果同步的从节点无法完成确认（例如由于从节点发生崩愤，或者网络故障，或任何其他原因），写入就不能视为成功。主节点会阻塞其后所有的操作，直到同步副本确认完成

**实践**

- 半同步复制：如果数据库启用了同步复制，通常意味着其中某一个从节点是同步的，而其他节点则是异步模式。万一同步的从节点变得不可用或性能下降，则将另一个异步的从节点提升为同步模式。这样可以保证至少有两个节点（即主节点和一个同步从节点）拥有最新的数据副本。这种配置有时也称为半同步
- 全异步复制：此时如果主节点发生失败且不可恢复，则有尚未复制到从节点的写请求都会丢失。这意味着即使向客户端确认了写操作，却无法保证数据的持久化。但全异步配置的优点则是，不管从节点上数据多么滞后，主节点总是可以继续响应写请求，系统的吞吐性能更好

### 配置新的从节点

常见的做法是使用主节点某一时刻数据副本的快照 (snapshot) 进行复制，主要操作步骤为：

1. 在某个时间点对主节点的数据副本产生一个一致性快照，这样避免长时间锁定整个数据库。目前大多数数据库都支持此功能，快照也是系统备份所必需的。而在某些情况下，可能需要第三方工具
2. 将此快照拷贝到新的从节点
3. 从节点连接到主节点并请求快照点之后所发生的数据更改日志。因为在第一步建快照时，快照与系统复制日志的某个确定位置相关联，这个位置信息在不同的系统有不同的称乎
4. 获得日志之后，从节点来应用这些快照点之后所有数据变更，这个过程称之为追赶。接下来，它可以继 处理主节点上新的数据变化。井重复这四个步骤

### 处理节点失效

**从节点失效：追赶式修复**

从节点的本地磁盘上都保存了副本收到的数据变更日志，如果从节点发生崩溃，则根据副本的复制日志，从节点就可以知道在发生故障之前锁所处理的最后一笔事务，然后连接到主节点，请求自那笔事务之后中断期间内所有的数据变更并应用到本地来追赶主节点即可。

**主节点失效：节点切换**

首先我们要确认主节点真正失效（一般基于超时机制），一经确认，我们就需要重新进行主节点选举，并通知客户端向新的主节点发送写请求。可能存在的问题如下，对于这些问题并没有简单的解决方案：

- 如果使用了异步复制且失效前新的主节点并未收到原主节点的所有数据，在选举之后原主节点又很快上线，那么新的主节点可能会收到冲突的写请求，这是因为原主节点并未意识到角色的变化。常见的解决方案是丢弃原主节点上未完成复制的写请求。
- 如果在数据库之外有其他系统依赖于数据库的内容并在一起协同使用，丢弃数据的方案就会非常危险
- 可能会存在脑裂（split-brain）问题，即两个节点同时都认为自己是主节点。它非常危险，两个节点都可能接受写请求，并且没有很好的解决冲突办法。一种安全应急方案是采取措施强制关闭其中一个节点。
- 设置合适的超时来检测主节点失效也是一个 Tradeoff

### 复制日志的实现

**基于语句的复制**

最简单的情况，主节点记录所执行的每个写请求（操作语句）并将该操作语句作为日志发送给从节点，看似简单但有一些不适用的场景：

- 任何调用非确定性函数的语句，如 NOW 获取当前时间，或 RAND 获取一个随机数等，可能会在不同的副本上产生不同的值。
- 如果语句中使用了自增列，或者依赖于数据库的现有数据（例如，UPDATE WHERE ＜某些条件＞），则所有副本必须按照完全相同的顺序执行，否则可能会带来不同的结果。进而，如果有多个同时并发执行 事务时，会有很大的限制
- 有副作用的语句（例如，触发器、存储过程、用户定义的函数等），可能会在每个副本上产生不同的副作用

有可能采取一些特殊措施来解决这些问题，但由于要考虑的情况太多，因此目前通常首选其他方案。

**基于预写日志（WAL）传输**

所有对数据库写入的字节序列都会被记入日志，因此可以使用完全相同的日志在另一个节点上构建副本。其主要缺点是日志描述的数据结果非常底 WAL 包含了哪些磁盘块的哪些字节发生改变，诸如此类的细节。这使得复制方案和存储引擎紧密搞合。如果数据库的存储格式从一个版本改为个版本，那么系统通常无法支持主从节点上运行不同版本的软件。

**基于行的逻辑日志复制**

复制和存储引擎采用不同的日志格式，这样复制与存储逻辑剥离。这种复制日志成为逻辑日志，以区分物理存储引擎的数据表示。

关系数据库的逻辑日志通常是指一系列记录来描述数据表行级别的写请求：

- 对于行插入，日志包含所有相关列的新值。
- 对于行删除，日志里有足够的信息来唯一标识已删除的行，通常是靠主键，但如果表上没有定义主键，就需要记录所有列的旧值。
- 对于行更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少包含所有已更新列的新值）。

如果一条事务涉及多行的修改，则会产生多个这样的日志记录，并在后面跟着一条记录，指出该事务已经提交。

**基于触发器的复制**

触发器支持注册自己的应用层代码，使得当数据库系统发生数据更改（写事务）时自动执行上述自定义代码。通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，实施必要的自定义应用层逻辑，例如将数据更改复制到另一个系统。

触发器支持注册自己的应用层代码，使得当数据库系统发生数据更改（写事务）时自动执行上述自定义代码。通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，实施必要的自定义应用层逻辑，例如将数据更改复制到另一个系统。

## 复制滞后的问题

主从复制要求所有写请求都经过主节点，而任何副本只能接受只读查询。如果一个应用正好从一个异步的从节点读取诗句，而该副本落后于主节点，那么应用可能会读到过期的信息，这会导致数据库中出现明显的不一致：如果同时对主节点和从节点发起相同的查询，可能会得到不同的结果。这种不一致只是一个暂时的状态，如果停止写数据库，经过一段时间之后，从节点最终会赶上并与主节点保持一致。这种效应被称为最终一致性。下面将介绍三个复制滞后可能出现的问题，并给出相应的解决思路：

### 读自己的写

用户在写入不就即查看数据，则新数据可能尚未到达从节点。对于这种情况，我们需要写后读一致性，也称为读写一致性（read-after-write）。该机制保证如果用户重新加载页面，他们总能看到自己最近提交的更新。但对其他用户则没有任何保证，这些用户的更新可能会在稍后才能刷新看到。

基于主从复制的系统可以通过如下方案实现写后读一致性：

* 如果用户访问可能会被修改的内容，从主节点读取，否则在从节点读取

### 单调读

假定用户从不同副本进行了多次读取，用户刷新一个网页，读请求可能被随机路由到某个从节点。如果该节点还未完成内容更新，则用户可能会发现网页内容出现了回滚的奇怪情况。即，他们本来看到了更新的内容，却在刷新网页之后又看到了过期的内容。

单调读一致性可以确保不会发生这种异常，这是一个比强一致性弱，但比最终一致性强的保证。当读取数据时，单调读保证，如果某个用户依次进行多次读取，则他绝不会看到回滚现象，即在读取较新值之后又发生读旧值的情况。

实现单调读的一种方式是保证每个用户总是从同一副本读取（不同的用户可以从不同副本读取）

### 前缀一致读

这种一致性要求对于一系列按照某个顺序发生的写要求，读取这些内容时也会按照当时写入的顺序。然而在分布式数据库中，不同的分区独立运行，不存在全局写入顺序，这就导致用户从数据库中读取数据时，可能会看到数据库的某部分旧值和另一部分新值。在后续章节中我们会继续讨论这个问题。

## 多主节点复制

主从复制有一个明显的缺点：系统只有一个主节点，会产生 single-point error。对该模型进行自然的扩展，则可以配置多个主节点，每个主节点都可以接受写操作，后面的复制流程类似：处理写的每个主节点都必须将该数据更改转发到所有其他节点。这就是多主节点（也称为主－主，或主动／主动）复制。此时，每个主节点同时扮演其他主节点的从节点。

### 适用场景

#### 多数据中心

为了容忍整个数据中心级别故障或者更接近用户，可以把数据库的副本横跨多个数据中心。而如果使用常规的基于主从的复制模型，主节点势必只能放在其中的某一个数据中心，而所有写请求都必须经过该数据中心。

有了多主节点复制模型，则可以在每个数据中心都配置主节点。在每个数据中心内，采用常规的主从复制方案；而在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。

#### 离线客户端操作

在这种场景下，要求应用在于网络断开连接后还要继续工作。在离线状态下的任何修改，会在下次设备上线时，与服务器以及其他设备同步。这种情况下，每个设备都有一个充当主节点的本地数据库（用来接受写请求），然后在所有设备之间采用异步方式同步这些多主节点的副本。

#### 协作编辑

实时协作编辑应用程序允许多个用户同时编辑文档，如 Google Docs。当一个用户编辑文档时，所做的更改会立即应用到本地副本（ Web浏览器或客户端应用程序），然后异步复制到服务器以及编辑同一文档的其他用户。如果要确保不会发生编辑冲突，则应用程序必须先将文档锁定，然后才能对其进行编辑。如果另一个用户想要编辑同一文档 首先必须等到第一个用户提交修改并释放。这种协作模式相当于主从复制模型下在主节点上执行事务操作。

### 处理写冲突

多主复制最大的问题是可能发生写冲突，因此必须有解决冲突的方案（正常情况下，主从复制不会有写冲突）

#### 同步与异步冲突检测

如果是主从复制，第二个写请求要么会被阻塞直到第一个完成，要么会被终止。然而在多主节点的复制模型下，这两个写请求都会成功，并且只能在稍后的时间点上才能异步检测到冲突。

理论上，可以做到同步冲突检测，即等待写请求完成对所有副本的同步，然后再通知用户写入成功 但是，这样做将会失去多主节点的主要优势：允许每个主节点独立接受写请求。如果确实想要同步方式冲突检测，或许应该考虑采用单主节点的主从复制模型。

#### 避免冲突

处理冲突最理想的策略是避免发生冲突，即如果应用层可以保证对特定记录的写请求总是通过同一个主节点，这样就不会发生写冲突

但是，有时可能需要改变事先指定的主节点，例如由于该数据中心发生故障，不得不将流量重新路由到其他数据中心，或者是因为用户已经漫游到另一个位置，因而更靠近新数据中心。此时，冲突避免方式不再有效，必须有措施来处理同时写入冲突的可能性

#### 收敛于一致状态

对干主从复制模型，数据更新符合顺序性原则，即如果同－个字段有多个更新，则最后一个写操作将决定该字段的最终值。对于多主节点复制模型，由于不存在这样的写入顺序，所以最终值也会变得不确定。如果每个副本都只是按照它所看到写入的顺序执行，那么数据最终将处于不一致状态。

可以通过如下方式实现收敛的冲突解决：

* 给每个写入分配唯一的 ID，挑选最高 ID 的写入作为胜利者，并将其他写入丢弃。该方法很流行但也很容易造成数据丢失。
* 为每个副本分配一个 ID，并指定规则，如序号高的副本写入始终优先于序号低的副本，该方法也可能导致数据丢失
* 以某种方式将这些值合并在一起
* 利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突

#### 自定义冲突解决逻辑

解决冲突最合适的方式可能还是依靠应用层，所以大多数多主节点复制模型都有工具来让用户编写应用代码来解决冲突。可以在写入时或在读取时执行这些代码逻辑：

* 在写入时执行
  * 只要数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突处理程序。 
* 在读取时执行：
  * 当检测到冲突，所有冲突写入值都会暂时保存下来。下一次读取数据时，会将数据的多个版本读返回给应用层。应用层可能会提示用户或自动解决冲突，井将最后的结果返回到数据库。

#### 自动冲突解决算法

* 无冲突的复制数据类型（CRDT，Conflict-free Replicated Datatypes）
* 可合并的持久数据结构（Mergeable persistent data）
* 操作转换（Operational transformaltion）

### 拓扑结构

复制的拓扑结构描述了写请求从一个节点的传播到其他节点的通信路径。最常见的拓扑结构是全部 - 至 - 全部，如 5-8(c)

![](/images/blog/ddia/chapter-5/topological.png)

在环形和星形拓扑中，写请求需要通过多个节点才能到达所有的副本，即中间节点需要转发从其它节点收到的数据变更。为防止无限循环，每个节点需要赋予一个唯一标识符，在复制日志中的每个写请求都标记了已通过的节点标识符。如果某个节点收到了包含自身标识符的数据更改，表明该请求已经被处理过，因此会忽略此变更请求，避免重复转发。

环形和星形拓扑的问题是，如果某一个节点发生了故障，在修复之前，会影响其他节点之间复制日志的转发。但另一方面，全链接拓扑也存在一些自身的问题。主要是存在某些网络链路比其他链路更快的情况（例如由于不同网络拥塞），从而导致复制日志之间的覆盖。

## 无主节点复制

放弃主节点，允许任何副本直接接受来自客户端的写请求。比较典型的数据库有 Dynamo, Riak, Cassandra, 和 Voldemort

### 节点失效时写入数据库

假设 个三副本数据库，其中一个副本当前不可用（例如正在重启以安装系统更新）。在基于主节点复制模型下，如果要继续处理写操作，则需要执行切换操作。对于无主节点配置，则不存在这样的切换操作。如下图所示，用户收到两个确认的回复之后就可认为写入成功，完全可以忽略其中一个副本无法写入的情况。

![](/images/blog/ddia/chapter-5/quorum-rw.png)

为了解决客户端读到过期数据的问题，一个客户端从数据库中读取数据肘，它不是向一个副本发送请
求，而是并行地发送到多个副本。客户端可能会得到不同节点的不同响应，包括某些节点的新值和某些节点的旧值。可以采用版本号技术确定哪个值更新。

**Dynamo 风格的数据存储系统经常使用以下两种机制：**

* 读修复：当客户端并行读取多个副本时可以检测到过期的返回值
* 反熵过程：一些数据存储有后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本

**读写 Quorum**

如果有 `n` 个副本，写人需要 `w` 个节点确认，读取必须至少查询 `r` 个节点， 则只要 `w + r > n` ，读取的节点中一定会包含最新值。满足上述这些 `r`，`w` 值的读／写操作称之为法定票数读（或仲裁读）或法定票数写（或仲裁写）。可以认为 `r` 和 `w` 是用于判定读、写是否有效的最低票数。

在 Dynamo 风格的数据库中，参数 `r`, `w`, `n` 通常是可以配置的。一个常见的选择是：`n` 为某奇数（通常为 3 或 5），`w = r = (n + 1) / 2`（向上舍入）。

![](/images/blog/ddia/chapter-5/tolerance.png)

### Quorum 一致性和局限性

* 如果采用了 sloppy quorum，写操作的 `w` 节点和读操作的 `r` 节点可能完全不同，无法保证读写请求一定存在重叠的节点
* 如果两个写操作同时发生，则无法明确先后顺序。合并并发写入时则由于时钟偏差问题可能会错误地抛弃某些写入。
* 如果写操作与读操作同时发 操作可能仅在一部分副本上完成。此时，读取时返回旧值还是新值存在不确定性。
* 如果某些副本上已经写入成功，而其他一些副本发生写入失败（例如磁盘已满），且总的成功副本数少于 `w`，那些 成功的副本上不会做回滚。这意味着尽管这样的写操作被视为失败，后续的读操作仍可能返回新值
* 如果具有新值的节点后来发生失效，但恢复数据来自某个 旧值，总的新值副本数会低于 `w`，这就打破了之前的判定条件。

### Sloppy Quorum

中文名为宽松仲裁，写入和读取仍然需要 `w` 和 `r` 个成功的相应，但包含了那些并不在先前指定的 `n` 个节点。这些节点提供了数据暂存的功能，也被称为临时节点。一旦网络问题得到解决，临时节点就要把接收到的写入全部发送到原始主节点上。这就是所谓的数据回传。